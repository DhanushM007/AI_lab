{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "469251aa-7746-4bcc-aec3-de8ee246ae08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-Table:\n",
      " [[-9.43819161e-01  1.72043878e+01 -1.03225851e+00 -9.39422087e-01]\n",
      " [ 5.61083163e+00  4.15049827e+01  2.26920171e-01  7.34839793e-01]\n",
      " [-7.69359882e-01  3.44733202e+01  1.16425106e+00  1.80133595e+00]\n",
      " [-5.85198506e-01  5.10238373e+01 -5.86721911e-01  7.30623190e+00]\n",
      " [-4.81366810e-01  5.85134234e+01 -4.09392640e-01 -3.94039900e-01]\n",
      " [-8.58300678e-01  1.14405595e+01 -7.04943295e-01  4.36785179e+01]\n",
      " [ 4.67332062e+00  5.48807122e+01  5.86746436e+00  8.10656897e+00]\n",
      " [ 4.38688407e+00  6.02903598e+01  1.78880617e+01  2.05059683e+01]\n",
      " [ 7.70411230e+00  6.98426373e+01  4.88133663e+00  1.19719214e+01]\n",
      " [ 6.94915094e+00  7.90004045e+01  1.42018000e+01  1.29711009e+01]\n",
      " [-4.57221479e-01  1.04352037e+00  1.34644265e+01  5.40973736e+01]\n",
      " [ 2.18789543e+01  2.78369244e+01  1.34055013e+01  6.21705762e+01]\n",
      " [ 3.27681228e+01  2.92132835e+01  3.82335245e+01  7.01899902e+01]\n",
      " [ 4.41479621e+01  4.33959054e+01  4.16496087e+01  7.91000000e+01]\n",
      " [ 5.53160646e+01  8.90000000e+01  5.65362133e+01  5.99055373e+01]\n",
      " [ 3.06270664e+01  2.63689413e-01 -6.79346521e-01  8.40681085e+00]\n",
      " [ 1.00761040e+01  2.49327890e+01  1.79315542e-02  6.12775029e+01]\n",
      " [-3.81208925e-01  7.87113288e+01  8.76103230e+00  9.57339857e-01]\n",
      " [ 2.85732878e+01  8.81760547e+01  2.60356013e+01 -1.00000000e-01]\n",
      " [ 5.49052530e+01  1.00000000e+02  6.42567711e+01  7.10433794e+01]\n",
      " [-3.09934558e-01  2.65739444e+00  3.29638578e+00  4.94318414e+01]\n",
      " [ 8.57686796e+00  1.80907074e+01  3.86052444e+00  7.74133851e+01]\n",
      " [ 9.32062330e+00  2.68987881e+01  3.31185970e+01  8.89997044e+01]\n",
      " [ 2.63129048e+01  5.87018162e+01  4.06365698e+01  9.99999996e+01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      "Optimal Policy:\n",
      " [['down' 'down' 'down' 'down' 'down']\n",
      " ['right' 'down' 'down' 'down' 'down']\n",
      " ['right' 'right' 'right' 'right' 'down']\n",
      " ['up' 'right' 'down' 'down' 'down']\n",
      " ['right' 'right' 'right' 'right' 'up']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "grid_size = 5\n",
    "num_states = 25\n",
    "actions = [\"up\", \"down\", \"left\", \"right\"]\n",
    "num_actions = 4\n",
    "\n",
    "rewards = np.full(num_states, -1)\n",
    "rewards[24] = 100\n",
    "\n",
    "q_table = np.zeros((num_states, num_actions))\n",
    "\n",
    "def take_action(state, action):\n",
    "    row = state // 5\n",
    "    col = state % 5\n",
    "\n",
    "    if action == 0:\n",
    "        row = max(0, row - 1)\n",
    "    elif action == 1:\n",
    "        row = min(4, row + 1)\n",
    "    elif action == 2:\n",
    "        col = max(0, col - 1)\n",
    "    elif action == 3:\n",
    "        col = min(4, col + 1)\n",
    "\n",
    "    return row * 5 + col\n",
    "\n",
    "learning_rate = 0.1\n",
    "discount = 0.9\n",
    "epsilon = 0.2\n",
    "\n",
    "for episode in range(500):\n",
    "\n",
    "    state = np.random.randint(0, 25)\n",
    "\n",
    "    while state != 24:\n",
    "\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = np.random.randint(0, 4)\n",
    "        else:\n",
    "            action = np.argmax(q_table[state])\n",
    "\n",
    "        next_state = take_action(state, action)\n",
    "\n",
    "        best_future = np.max(q_table[next_state])\n",
    "\n",
    "        q_table[state, action] = q_table[state, action] + \\\n",
    "            learning_rate * (rewards[next_state] + discount * best_future - q_table[state, action])\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "print(\"Q-Table:\\n\", q_table)\n",
    "\n",
    "best_actions = np.argmax(q_table, axis=1)\n",
    "policy = np.array([actions[a] for a in best_actions])\n",
    "print(\"\\nOptimal Policy:\\n\", policy.reshape(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80f30b6-eaeb-4d99-b718-b88c1c86c1df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
