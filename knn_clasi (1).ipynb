{
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "a35eeb9f-df70-4ab1-a243-2d2025888eb0",
      "cell_type": "markdown",
      "source": "# Introduction to the JupyterLab and Jupyter Notebooks\n\nThis is a short introduction to two of the flagship tools created by [the Jupyter Community](https://jupyter.org).\n\n> **âš ï¸Experimental!âš ï¸**: This is an experimental interface provided by the [JupyterLite project](https://jupyterlite.readthedocs.io/en/latest/). It embeds an entire JupyterLab interface, with many popular packages for scientific computing, in your browser. There may be minor differences in behavior between JupyterLite and the JupyterLab you install locally. You may also encounter some bugs or unexpected behavior. To report any issues, or to get involved with the JupyterLite project, see [the JupyterLite repository](https://github.com/jupyterlite/jupyterlite/issues?q=is%3Aissue+is%3Aopen+sort%3Aupdated-desc).\n\n## JupyterLab ðŸ§ª\n\n**JupyterLab** is a next-generation web-based user interface for Project Jupyter. It enables you to work with documents and activities such as Jupyter notebooks, text editors, terminals, and custom components in a flexible, integrated, and extensible manner. It is the interface that you're looking at right now.\n\n**For an overview of the JupyterLab interface**, see the **JupyterLab Welcome Tour** on this page, by going to `Help -> Welcome Tour` and following the prompts.\n\n> **See Also**: For a more in-depth tour of JupyterLab with a full environment that runs in the cloud, see [the JupyterLab introduction on Binder](https://mybinder.org/v2/gh/jupyterlab/jupyterlab-demo/HEAD?urlpath=lab/tree/demo).\n\n## Jupyter Notebooks ðŸ““\n\n**Jupyter Notebooks** are a community standard for communicating and performing interactive computing. They are a document that blends computations, outputs, explanatory text, mathematics, images, and rich media representations of objects.\n\nJupyterLab is one interface used to create and interact with Jupyter Notebooks.\n\n**For an overview of Jupyter Notebooks**, see the **JupyterLab Welcome Tour** on this page, by going to `Help -> Notebook Tour` and following the prompts.\n\n> **See Also**: For a more in-depth tour of Jupyter Notebooks and the Classic Jupyter Notebook interface, see [the Jupyter Notebook IPython tutorial on Binder](https://mybinder.org/v2/gh/ipython/ipython-in-depth/HEAD?urlpath=tree/binder/Index.ipynb).\n\n## An example: visualizing data in the notebook âœ¨\n\nBelow is an example of a code cell. We'll visualize some simple data using two popular packages in Python. We'll use [NumPy](https://numpy.org/) to create some random data, and [Matplotlib](https://matplotlib.org) to visualize it.\n\nNote how the code and the results of running the code are bundled together.",
      "metadata": {}
    },
    {
      "id": "fe55883a-6887-43dd-9498-5333a51799e2",
      "cell_type": "code",
      "source": "import numpy as np\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\n\ndef euclidean_distance(point1, point2):\n    return np.sqrt(np.sum((point1 - point2) ** 2))\n\ndef knn_classify(x_train, y_train, x_test, k=3):\n    predictions = []\n    for test_point in x_test:\n        distances = [euclidean_distance(test_point, train_point) for train_point in x_train]\n        nearest_indices = np.argsort(distances)[:k]\n        nearest_labels = [y_train[i] for i in nearest_indices]\n        most_common = Counter(nearest_labels).most_common(1)[0][0]\n        predictions.append(most_common)\n    return predictions\n\ndata = load_iris()\nx = data.data\ny = data.target\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\nk = 3\npredictions = knn_classify(x_train, y_train, x_test, k=k)\n\ncorrect = 0\nincorrect = 0\n\nprint(\"\\nPrediction Results:\")\nfor i, (pred, actual) in enumerate(zip(predictions, y_test)):\n    if pred == actual:\n        correct += 1\n        print(f\"Test Sample {i+1}: Correct (Predicted: {pred}, Actual: {actual})\")\n    else:\n        incorrect += 1\n        print(f\"Test Sample {i+1}: Incorrect (Predicted: {pred}, Actual: {actual})\")\n\ntotal = correct + incorrect\naccuracy = correct / total * 100\nprint(f\"\\nTotal Correct Predictions: {correct}\")\nprint(f\"Total Incorrect Predictions: {incorrect}\")\nprint(f\"Accuracy: {accuracy:.2f}%\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\nPrediction Results:\nTest Sample 1: Correct (Predicted: 1, Actual: 1)\nTest Sample 2: Correct (Predicted: 0, Actual: 0)\nTest Sample 3: Correct (Predicted: 2, Actual: 2)\nTest Sample 4: Correct (Predicted: 1, Actual: 1)\nTest Sample 5: Correct (Predicted: 1, Actual: 1)\nTest Sample 6: Correct (Predicted: 0, Actual: 0)\nTest Sample 7: Correct (Predicted: 1, Actual: 1)\nTest Sample 8: Correct (Predicted: 2, Actual: 2)\nTest Sample 9: Correct (Predicted: 1, Actual: 1)\nTest Sample 10: Correct (Predicted: 1, Actual: 1)\nTest Sample 11: Correct (Predicted: 2, Actual: 2)\nTest Sample 12: Correct (Predicted: 0, Actual: 0)\nTest Sample 13: Correct (Predicted: 0, Actual: 0)\nTest Sample 14: Correct (Predicted: 0, Actual: 0)\nTest Sample 15: Correct (Predicted: 0, Actual: 0)\nTest Sample 16: Correct (Predicted: 1, Actual: 1)\nTest Sample 17: Correct (Predicted: 2, Actual: 2)\nTest Sample 18: Correct (Predicted: 1, Actual: 1)\nTest Sample 19: Correct (Predicted: 1, Actual: 1)\nTest Sample 20: Correct (Predicted: 2, Actual: 2)\nTest Sample 21: Correct (Predicted: 0, Actual: 0)\nTest Sample 22: Correct (Predicted: 2, Actual: 2)\nTest Sample 23: Correct (Predicted: 0, Actual: 0)\nTest Sample 24: Correct (Predicted: 2, Actual: 2)\nTest Sample 25: Correct (Predicted: 2, Actual: 2)\nTest Sample 26: Correct (Predicted: 2, Actual: 2)\nTest Sample 27: Correct (Predicted: 2, Actual: 2)\nTest Sample 28: Correct (Predicted: 2, Actual: 2)\nTest Sample 29: Correct (Predicted: 0, Actual: 0)\nTest Sample 30: Correct (Predicted: 0, Actual: 0)\nTest Sample 31: Correct (Predicted: 0, Actual: 0)\nTest Sample 32: Correct (Predicted: 0, Actual: 0)\nTest Sample 33: Correct (Predicted: 1, Actual: 1)\nTest Sample 34: Correct (Predicted: 0, Actual: 0)\nTest Sample 35: Correct (Predicted: 0, Actual: 0)\nTest Sample 36: Correct (Predicted: 2, Actual: 2)\nTest Sample 37: Correct (Predicted: 1, Actual: 1)\nTest Sample 38: Correct (Predicted: 0, Actual: 0)\nTest Sample 39: Correct (Predicted: 0, Actual: 0)\nTest Sample 40: Correct (Predicted: 0, Actual: 0)\nTest Sample 41: Correct (Predicted: 2, Actual: 2)\nTest Sample 42: Correct (Predicted: 1, Actual: 1)\nTest Sample 43: Correct (Predicted: 1, Actual: 1)\nTest Sample 44: Correct (Predicted: 0, Actual: 0)\nTest Sample 45: Correct (Predicted: 0, Actual: 0)\n\nTotal Correct Predictions: 45\nTotal Incorrect Predictions: 0\nAccuracy: 100.00%\n"
        }
      ],
      "execution_count": 9
    },
    {
      "id": "5aaabb3e-c262-4689-abe1-15b25b2e03db",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}